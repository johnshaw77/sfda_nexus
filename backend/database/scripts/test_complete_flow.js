import chatService from "../../src/services/chat.service.js";
import AIService from "../../src/services/ai.service.js";

// å®Œæ•´èŠå¤©æµç¨‹æ¸¬è©¦
async function testCompleteFlow() {
  console.log("ğŸ§ª é–‹å§‹å®Œæ•´èŠå¤©æµç¨‹æ¸¬è©¦...\n");

  try {
    const userMessage = "è«‹æŸ¥è©¢å·¥è™Ÿ A123456 çš„å“¡å·¥è³‡è¨Š";
    console.log("ğŸ‘¤ ç”¨æˆ¶æ¶ˆæ¯:", userMessage);

    // 1. ç”Ÿæˆç³»çµ±æç¤ºè©
    console.log("\nğŸ“ æ­¥é©Ÿ 1: ç”Ÿæˆç³»çµ±æç¤ºè©");
    const systemPrompt = await chatService.generateSystemPrompt(
      "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ•¸ä½ç§˜æ›¸ã€‚",
      {
        user_id: 1,
        conversation_id: 1,
        model_type: "ollama",
      }
    );

    console.log("âœ… ç³»çµ±æç¤ºè©ç”Ÿæˆå®Œæˆ");
    console.log("é•·åº¦:", systemPrompt.length);
    console.log("é è¦½:", systemPrompt.substring(0, 300) + "...");

    // 2. æº–å‚™ AI èª¿ç”¨åƒæ•¸
    console.log("\nğŸ¤– æ­¥é©Ÿ 2: èª¿ç”¨ AI æ¨¡å‹");
    const aiOptions = {
      provider: "ollama",
      model: "qwen3:8b",
      endpoint_url: "http://localhost:11434",
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userMessage,
        },
      ],
      temperature: 0.7,
      max_tokens: 2048,
    };

    console.log("AI èª¿ç”¨åƒæ•¸:", {
      provider: aiOptions.provider,
      model: aiOptions.model,
      messagesCount: aiOptions.messages.length,
      systemPromptLength: aiOptions.messages[0].content.length,
    });

    // 3. èª¿ç”¨ AI æ¨¡å‹
    const aiResponse = await AIService.callModel(aiOptions);

    console.log("âœ… AI æ¨¡å‹èª¿ç”¨å®Œæˆ");
    console.log("AI å›æ‡‰:", {
      provider: aiResponse.provider,
      model: aiResponse.model,
      contentLength: aiResponse.content.length,
      tokensUsed: aiResponse.tokens_used,
      processingTime: aiResponse.processing_time,
    });
    console.log("AI å›æ‡‰å…§å®¹:", aiResponse.content);

    // 4. è™•ç†å·¥å…·èª¿ç”¨
    console.log("\nğŸ”§ æ­¥é©Ÿ 3: è™•ç†å·¥å…·èª¿ç”¨");
    const chatResult = await chatService.processChatMessage(
      aiResponse.content,
      {
        user_id: 1,
        conversation_id: 1,
        model_id: "qwen3:8b",
      }
    );

    console.log("âœ… å·¥å…·èª¿ç”¨è™•ç†å®Œæˆ");
    console.log("è™•ç†çµæœ:", {
      hasToolCalls: chatResult.has_tool_calls,
      toolCallsCount: chatResult.tool_calls?.length || 0,
      toolResultsCount: chatResult.tool_results?.length || 0,
      usedSecondaryAI: chatResult.used_secondary_ai || false,
    });

    // 5. é¡¯ç¤ºè©³ç´°çµæœ
    if (chatResult.has_tool_calls) {
      console.log("\nğŸ”§ å·¥å…·èª¿ç”¨è©³æƒ…:");
      chatResult.tool_calls?.forEach((call, index) => {
        console.log(`å·¥å…· ${index + 1}:`, {
          name: call.name,
          format: call.format,
          parameters: call.parameters,
        });
      });

      console.log("\nğŸ“Š å·¥å…·åŸ·è¡Œçµæœ:");
      chatResult.tool_results?.forEach((result, index) => {
        console.log(`çµæœ ${index + 1}:`, {
          toolName: result.tool_name,
          success: result.success,
          executionTime: result.execution_time,
          dataPreview:
            typeof result.data === "object"
              ? JSON.stringify(result.data).substring(0, 200) + "..."
              : String(result.data).substring(0, 200),
        });
      });
    }

    console.log("\nğŸ“ æœ€çµ‚å›æ‡‰:");
    console.log(chatResult.final_response || aiResponse.content);

    // 6. æ¸¬è©¦çµæœç¸½çµ
    console.log("\nğŸ¯ æ¸¬è©¦çµæœç¸½çµ:");
    console.log("- ç³»çµ±æç¤ºè©ç”Ÿæˆ: âœ…");
    console.log("- AI æ¨¡å‹èª¿ç”¨: âœ…");
    console.log("- å·¥å…·èª¿ç”¨æª¢æ¸¬:", chatResult.has_tool_calls ? "âœ…" : "âŒ");
    console.log(
      "- å·¥å…·åŸ·è¡Œ:",
      chatResult.tool_results?.some((r) => r.success) ? "âœ…" : "âŒ"
    );
    console.log("- æœ€çµ‚å›æ‡‰ç”Ÿæˆ: âœ…");
  } catch (error) {
    console.error("âŒ æ¸¬è©¦å¤±æ•—:", error.message);
    console.error("éŒ¯èª¤å †ç–Š:", error.stack);
  }
}

// åŸ·è¡Œæ¸¬è©¦
testCompleteFlow();
