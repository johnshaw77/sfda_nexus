/**
 * æ¸¬è©¦ Llava å¤šæ¨¡æ…‹åŠŸèƒ½
 * é©—è­‰ llava æ¨¡å‹æ˜¯å¦èƒ½è™•ç†åœ–ç‰‡
 */

import { AIService } from "../../src/services/ai.service.js";

console.log("ğŸ§ª æ¸¬è©¦ Llava å¤šæ¨¡æ…‹åŠŸèƒ½...\n");

async function testLlavaMultimodal() {
  try {
    // 1. æ¸¬è©¦ç´”æ–‡å­—å°è©±
    console.log("=== 1. æ¸¬è©¦ç´”æ–‡å­—å°è©± ===");
    const textOnlyMessages = [
      { role: "user", content: "ä½ å¥½ï¼Œè«‹å‘Šè¨´æˆ‘ä½ æ˜¯ä»€éº¼æ¨¡å‹ï¼Ÿ" },
    ];

    console.log("ç™¼é€ç´”æ–‡å­—æ¶ˆæ¯åˆ° llava...");
    const textResponse = await AIService.callModel({
      provider: "ollama",
      model: "llava:latest",
      messages: textOnlyMessages,
      temperature: 0.7,
      max_tokens: 1000,
      stream: false,
    });

    console.log("âœ… ç´”æ–‡å­—å›æ‡‰æˆåŠŸ:");
    console.log(textResponse.content.substring(0, 200) + "...\n");

    // 2. æ¸¬è©¦å¤šæ¨¡æ…‹æ ¼å¼ï¼ˆæ¨¡æ“¬åœ–ç‰‡ï¼‰
    console.log("=== 2. æ¸¬è©¦å¤šæ¨¡æ…‹æ ¼å¼ ===");
    const multimodalMessages = [
      {
        role: "user",
        content: [
          { type: "text", text: "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹" },
          {
            type: "image_url",
            image_url: {
              url: "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k=",
            },
          },
        ],
      },
    ];

    console.log("ç™¼é€å¤šæ¨¡æ…‹æ¶ˆæ¯åˆ° llava...");
    console.log("æ¶ˆæ¯æ ¼å¼:", JSON.stringify(multimodalMessages[0], null, 2));

    try {
      const multimodalResponse = await AIService.callModel({
        provider: "ollama",
        model: "llava:latest",
        messages: multimodalMessages,
        temperature: 0.7,
        max_tokens: 1000,
        stream: false,
      });

      console.log("âœ… å¤šæ¨¡æ…‹å›æ‡‰æˆåŠŸ:");
      console.log(multimodalResponse.content.substring(0, 300) + "...\n");
    } catch (error) {
      console.log("âŒ å¤šæ¨¡æ…‹æ¸¬è©¦å¤±æ•—:");
      console.log("éŒ¯èª¤é¡å‹:", error.constructor.name);
      console.log("éŒ¯èª¤æ¶ˆæ¯:", error.message);
      if (error.response?.data) {
        console.log("API éŒ¯èª¤è©³æƒ…:", error.response.data);
      }
      console.log("");
    }

    // 3. æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
    console.log("=== 3. æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹ ===");
    try {
      const response = await fetch("http://localhost:11434/api/tags");
      const data = await response.json();
      console.log("âœ… Ollama æœå‹™æ­£å¸¸");
      const llavaModel = data.models?.find((m) => m.name.includes("llava"));
      if (llavaModel) {
        console.log("âœ… æ‰¾åˆ° llava æ¨¡å‹:", llavaModel.name);
        console.log(
          "   å¤§å°:",
          Math.round((llavaModel.size / 1024 / 1024 / 1024) * 100) / 100,
          "GB"
        );
      } else {
        console.log("âŒ æœªæ‰¾åˆ° llava æ¨¡å‹");
      }
    } catch (error) {
      console.log("âŒ Ollama æœå‹™é€£æ¥å¤±æ•—:", error.message);
    }
  } catch (error) {
    console.error("æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤:", error);
  }
}

testLlavaMultimodal();
